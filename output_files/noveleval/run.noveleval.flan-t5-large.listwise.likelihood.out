/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]32it [00:00, 314.51it/s]71it [00:00, 356.84it/s]153it [00:00, 563.49it/s]210it [00:00, 494.22it/s]261it [00:00, 467.41it/s]309it [00:00, 456.95it/s]505it [00:00, 902.67it/s]600it [00:00, 809.99it/s]700it [00:01, 859.03it/s]790it [00:01, 822.34it/s]969it [00:01, 1086.11it/s]1083it [00:01, 1035.03it/s]1191it [00:01, 936.62it/s] 1381it [00:01, 1180.54it/s]1506it [00:01, 850.57it/s] 1608it [00:02, 760.24it/s]1757it [00:02, 910.88it/s]1864it [00:02, 904.71it/s]1976it [00:02, 951.85it/s]2080it [00:02, 926.70it/s]2179it [00:02, 789.73it/s]2265it [00:02, 736.70it/s]2344it [00:02, 715.10it/s]2506it [00:03, 931.76it/s]2607it [00:03, 910.20it/s]2703it [00:03, 787.64it/s]2832it [00:03, 907.55it/s]2930it [00:03, 784.65it/s]3016it [00:03, 745.04it/s]3096it [00:03, 753.60it/s]3208it [00:03, 845.32it/s]3297it [00:04, 810.14it/s]3397it [00:04, 855.87it/s]3486it [00:04, 740.95it/s]3565it [00:04, 636.77it/s]3822it [00:04, 1083.55it/s]3947it [00:04, 1085.16it/s]3966it [00:04, 846.98it/s] 
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:12<04:07, 12.40s/it] 10%|▉         | 2/21 [00:21<03:18, 10.45s/it] 14%|█▍        | 3/21 [00:33<03:20, 11.15s/it] 19%|█▉        | 4/21 [00:46<03:18, 11.70s/it] 24%|██▍       | 5/21 [00:59<03:17, 12.35s/it] 29%|██▊       | 6/21 [01:14<03:18, 13.24s/it] 33%|███▎      | 7/21 [01:28<03:11, 13.66s/it] 38%|███▊      | 8/21 [01:43<03:01, 13.95s/it] 43%|████▎     | 9/21 [01:58<02:49, 14.16s/it] 48%|████▊     | 10/21 [02:13<02:38, 14.41s/it] 52%|█████▏    | 11/21 [02:25<02:19, 13.92s/it] 57%|█████▋    | 12/21 [02:38<02:00, 13.42s/it] 62%|██████▏   | 13/21 [02:50<01:44, 13.06s/it] 67%|██████▋   | 14/21 [03:02<01:30, 12.86s/it] 71%|███████▏  | 15/21 [03:15<01:16, 12.78s/it] 76%|███████▌  | 16/21 [03:29<01:06, 13.28s/it] 81%|████████  | 17/21 [03:42<00:51, 12.92s/it] 86%|████████▌ | 18/21 [03:53<00:37, 12.61s/it] 90%|█████████ | 19/21 [04:05<00:24, 12.36s/it] 95%|█████████▌| 20/21 [04:17<00:12, 12.19s/it]100%|██████████| 21/21 [04:29<00:00, 12.09s/it]100%|██████████| 21/21 [04:29<00:00, 12.82s/it]
Avg comparisons: 242.14285714285714
Avg prompt tokens: 114044.95238095238
Avg completion tokens: 0.0
Avg time per query: 12.824555896577381
