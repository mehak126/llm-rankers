/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]
0it [00:00, ?it/s]27it [00:00, 267.74it/s]60it [00:00, 301.70it/s]95it [00:00, 320.84it/s]170it [00:00, 486.60it/s]219it [00:00, 427.64it/s]263it [00:00, 402.57it/s]305it [00:00, 389.72it/s]494it [00:00, 814.31it/s]581it [00:01, 640.76it/s]692it [00:01, 752.87it/s]777it [00:01, 662.89it/s]962it [00:01, 938.48it/s]1069it [00:01, 835.72it/s]1167it [00:01, 866.69it/s]1262it [00:01, 775.49it/s]1410it [00:01, 939.37it/s]1513it [00:02, 711.41it/s]1598it [00:02, 619.08it/s]1749it [00:02, 798.13it/s]1845it [00:02, 726.56it/s]1968it [00:02, 833.40it/s]2064it [00:02, 746.14it/s]2149it [00:03, 715.77it/s]2228it [00:03, 654.63it/s]2299it [00:03, 554.89it/s]2480it [00:03, 817.70it/s]2576it [00:03, 673.79it/s]2666it [00:03, 720.58it/s]2750it [00:03, 661.10it/s]2848it [00:04, 728.65it/s]2929it [00:04, 648.43it/s]3001it [00:04, 632.01it/s]3069it [00:04, 565.48it/s]3201it [00:04, 735.50it/s]3282it [00:04, 647.75it/s]3389it [00:04, 743.30it/s]3471it [00:05, 639.63it/s]3542it [00:05, 546.30it/s]3790it [00:05, 961.00it/s]3908it [00:05, 788.96it/s]3966it [00:05, 708.19it/s]
  0%|          | 0/21 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors
  5%|▍         | 1/21 [00:07<02:31,  7.58s/it] 10%|▉         | 2/21 [00:14<02:15,  7.16s/it] 14%|█▍        | 3/21 [00:21<02:11,  7.32s/it] 19%|█▉        | 4/21 [00:29<02:02,  7.21s/it] 24%|██▍       | 5/21 [00:36<01:56,  7.30s/it] 29%|██▊       | 6/21 [00:44<01:51,  7.43s/it] 33%|███▎      | 7/21 [00:51<01:45,  7.51s/it] 38%|███▊      | 8/21 [00:59<01:37,  7.50s/it] 43%|████▎     | 9/21 [01:06<01:29,  7.49s/it] 48%|████▊     | 10/21 [01:14<01:22,  7.54s/it] 52%|█████▏    | 11/21 [01:21<01:14,  7.50s/it] 57%|█████▋    | 12/21 [01:29<01:07,  7.47s/it] 62%|██████▏   | 13/21 [01:36<00:59,  7.47s/it] 67%|██████▋   | 14/21 [01:43<00:51,  7.40s/it] 71%|███████▏  | 15/21 [01:51<00:44,  7.48s/it] 76%|███████▌  | 16/21 [01:59<00:37,  7.53s/it] 81%|████████  | 17/21 [02:07<00:30,  7.60s/it] 86%|████████▌ | 18/21 [02:14<00:22,  7.61s/it] 90%|█████████ | 19/21 [02:22<00:15,  7.61s/it] 95%|█████████▌| 20/21 [02:29<00:07,  7.53s/it]100%|██████████| 21/21 [02:37<00:00,  7.74s/it]100%|██████████| 21/21 [02:37<00:00,  7.52s/it]
Avg comparisons: 72.9047619047619
Avg prompt tokens: 41947.09523809524
Avg completion tokens: 364.5238095238095
Avg time per query: 7.515979732785906
