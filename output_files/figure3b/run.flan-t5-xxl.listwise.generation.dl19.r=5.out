/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:07,  1.77s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:03<00:04,  1.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:04<00:03,  1.59s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:06<00:01,  1.58s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:07<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:07<00:00,  1.49s/it]
0it [00:00, ?it/s]60it [00:00, 588.36it/s]1018it [00:00, 5821.69it/s]1604it [00:00, 4641.95it/s]2093it [00:00, 3952.19it/s]3055it [00:00, 5575.18it/s]4011it [00:00, 6727.42it/s]4738it [00:00, 5834.46it/s]5375it [00:01, 5146.56it/s]6058it [00:01, 5548.74it/s]7018it [00:01, 6589.48it/s]7727it [00:01, 6323.15it/s]8394it [00:01, 5160.87it/s]9061it [00:01, 5509.39it/s]10017it [00:01, 6514.86it/s]10723it [00:01, 5993.31it/s]11366it [00:02, 5206.37it/s]12054it [00:02, 5589.26it/s]13011it [00:02, 6568.22it/s]13715it [00:02, 5814.69it/s]14342it [00:02, 5089.34it/s]15054it [00:02, 5559.48it/s]16011it [00:02, 6540.60it/s]16715it [00:02, 5989.79it/s]17355it [00:03, 5230.85it/s]18065it [00:03, 5670.63it/s]19030it [00:03, 6651.08it/s]19742it [00:03, 6241.81it/s]20402it [00:03, 5325.49it/s]21055it [00:03, 5608.48it/s]22011it [00:03, 6574.31it/s]22712it [00:03, 6047.01it/s]23353it [00:04, 5297.52it/s]24054it [00:04, 5698.73it/s]25008it [00:04, 6659.19it/s]25716it [00:04, 5977.14it/s]26353it [00:04, 5361.77it/s]27060it [00:04, 5760.22it/s]28018it [00:04, 6733.35it/s]28732it [00:04, 6255.31it/s]29391it [00:05, 5264.33it/s]30055it [00:05, 5581.22it/s]31008it [00:05, 6551.41it/s]31710it [00:05, 5913.76it/s]32343it [00:05, 5203.35it/s]33053it [00:05, 5647.14it/s]34009it [00:05, 6619.96it/s]34717it [00:06, 5882.14it/s]35349it [00:06, 5299.10it/s]36066it [00:06, 5743.50it/s]37024it [00:06, 6715.45it/s]37739it [00:06, 6428.74it/s]38414it [00:06, 5534.91it/s]39057it [00:06, 5748.03it/s]40010it [00:06, 6717.68it/s]40721it [00:07, 5929.13it/s]41356it [00:07, 5087.03it/s]42061it [00:07, 5524.32it/s]43000it [00:07, 5855.39it/s]
  0%|          | 0/43 [00:00<?, ?it/s]/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
  2%|▏         | 1/43 [01:48<1:15:53, 108.43s/it]  5%|▍         | 2/43 [03:26<1:09:58, 102.41s/it]  7%|▋         | 3/43 [05:22<1:12:18, 108.45s/it]  9%|▉         | 4/43 [07:14<1:11:22, 109.80s/it] 12%|█▏        | 5/43 [08:57<1:08:04, 107.50s/it] 14%|█▍        | 6/43 [10:45<1:06:26, 107.73s/it] 16%|█▋        | 7/43 [12:36<1:05:14, 108.74s/it] 19%|█▊        | 8/43 [14:27<1:03:55, 109.57s/it] 21%|██        | 9/43 [15:56<58:18, 102.89s/it]   23%|██▎       | 10/43 [17:56<59:35, 108.35s/it] 26%|██▌       | 11/43 [19:42<57:27, 107.72s/it] 28%|██▊       | 12/43 [21:35<56:21, 109.09s/it] 30%|███       | 13/43 [23:08<52:07, 104.25s/it] 33%|███▎      | 14/43 [24:50<50:05, 103.65s/it] 35%|███▍      | 15/43 [26:40<49:13, 105.50s/it] 37%|███▋      | 16/43 [28:08<45:08, 100.32s/it] 40%|███▉      | 17/43 [29:54<44:09, 101.89s/it] 42%|████▏     | 18/43 [31:36<42:28, 101.94s/it] 44%|████▍     | 19/43 [33:13<40:15, 100.65s/it] 47%|████▋     | 20/43 [35:12<40:40, 106.09s/it] 49%|████▉     | 21/43 [37:06<39:44, 108.39s/it] 51%|█████     | 22/43 [38:38<36:12, 103.44s/it] 53%|█████▎    | 23/43 [40:32<35:35, 106.76s/it] 56%|█████▌    | 24/43 [42:01<32:05, 101.33s/it] 58%|█████▊    | 25/43 [43:27<28:59, 96.61s/it]  60%|██████    | 26/43 [45:11<28:02, 98.95s/it] 63%|██████▎   | 27/43 [46:49<26:19, 98.71s/it] 65%|██████▌   | 28/43 [48:33<25:04, 100.30s/it] 67%|██████▋   | 29/43 [50:03<22:41, 97.28s/it]  70%|██████▉   | 30/43 [51:41<21:06, 97.46s/it] 72%|███████▏  | 31/43 [53:11<19:02, 95.21s/it] 74%|███████▍  | 32/43 [54:55<17:54, 97.67s/it] 77%|███████▋  | 33/43 [56:32<16:16, 97.66s/it] 79%|███████▉  | 34/43 [57:56<14:02, 93.58s/it] 81%|████████▏ | 35/43 [59:33<12:36, 94.51s/it] 84%|████████▎ | 36/43 [1:01:33<11:55, 102.15s/it] 86%|████████▌ | 37/43 [1:03:12<10:06, 101.11s/it] 88%|████████▊ | 38/43 [1:05:00<08:36, 103.26s/it] 91%|█████████ | 39/43 [1:06:39<06:48, 102.12s/it] 93%|█████████▎| 40/43 [1:08:27<05:11, 103.73s/it] 95%|█████████▌| 41/43 [1:10:04<03:23, 101.74s/it] 98%|█████████▊| 42/43 [1:11:42<01:40, 100.69s/it]100%|██████████| 43/43 [1:13:47<00:00, 107.86s/it]100%|██████████| 43/43 [1:13:47<00:00, 102.96s/it]
Avg comparisons: 245.0
Avg prompt tokens: 119319.27906976744
Avg completion tokens: 2818.813953488372
Avg time per query: 102.96114054946013
