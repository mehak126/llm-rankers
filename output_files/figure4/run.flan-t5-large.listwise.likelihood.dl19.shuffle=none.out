/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]56it [00:00, 558.96it/s]1010it [00:00, 5834.44it/s]1594it [00:00, 4135.36it/s]2054it [00:00, 4273.55it/s]3012it [00:00, 5913.96it/s]3649it [00:00, 5087.98it/s]4203it [00:00, 4099.39it/s]5057it [00:01, 5130.96it/s]6018it [00:01, 6237.83it/s]6721it [00:01, 5582.68it/s]7344it [00:01, 5031.69it/s]8046it [00:01, 5472.50it/s]8640it [00:01, 5379.04it/s]9210it [00:01, 4577.49it/s]10048it [00:01, 5457.28it/s]11004it [00:02, 6478.62it/s]11708it [00:02, 5586.33it/s]12324it [00:02, 4622.50it/s]13049it [00:02, 5192.47it/s]14002it [00:02, 6195.16it/s]14693it [00:02, 5366.11it/s]15295it [00:03, 4462.18it/s]16060it [00:03, 5122.00it/s]17020it [00:03, 6156.03it/s]17716it [00:03, 5743.40it/s]18350it [00:03, 5225.06it/s]19050it [00:03, 5623.10it/s]20001it [00:03, 6578.89it/s]20707it [00:03, 5514.09it/s]21317it [00:04, 4535.41it/s]22058it [00:04, 5135.72it/s]23020it [00:04, 6159.49it/s]23712it [00:04, 5783.21it/s]24346it [00:04, 4684.65it/s]25058it [00:04, 5199.05it/s]26014it [00:04, 6226.48it/s]26711it [00:04, 5930.21it/s]27357it [00:05, 5105.23it/s]28056it [00:05, 5527.79it/s]29006it [00:05, 6506.92it/s]29712it [00:05, 5473.97it/s]30322it [00:05, 4478.11it/s]31059it [00:05, 5077.19it/s]32017it [00:05, 6111.56it/s]32709it [00:06, 5738.99it/s]33341it [00:06, 4733.92it/s]34056it [00:06, 5254.17it/s]35010it [00:06, 6260.67it/s]35707it [00:06, 5826.27it/s]36342it [00:06, 5101.88it/s]37054it [00:06, 5548.62it/s]38017it [00:07, 6558.12it/s]38726it [00:07, 5825.26it/s]39358it [00:07, 4850.56it/s]40045it [00:07, 5281.45it/s]41004it [00:07, 6307.61it/s]41697it [00:07, 5330.06it/s]42296it [00:07, 4743.61it/s]43000it [00:07, 5438.41it/s]
  0%|          | 0/43 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors
  2%|▏         | 1/43 [00:12<08:53, 12.70s/it]  5%|▍         | 2/43 [00:25<08:32, 12.49s/it]  7%|▋         | 3/43 [00:37<08:16, 12.41s/it]  9%|▉         | 4/43 [00:49<08:02, 12.37s/it] 12%|█▏        | 5/43 [01:02<07:49, 12.35s/it] 14%|█▍        | 6/43 [01:14<07:35, 12.32s/it] 16%|█▋        | 7/43 [01:26<07:23, 12.31s/it] 19%|█▊        | 8/43 [01:38<07:09, 12.28s/it] 21%|██        | 9/43 [01:51<06:58, 12.29s/it] 23%|██▎       | 10/43 [02:03<06:45, 12.28s/it] 26%|██▌       | 11/43 [02:15<06:32, 12.28s/it] 28%|██▊       | 12/43 [02:27<06:20, 12.28s/it] 30%|███       | 13/43 [02:40<06:08, 12.28s/it] 33%|███▎      | 14/43 [02:52<05:56, 12.28s/it] 35%|███▍      | 15/43 [03:04<05:43, 12.28s/it] 37%|███▋      | 16/43 [03:16<05:31, 12.28s/it] 40%|███▉      | 17/43 [03:29<05:19, 12.28s/it] 42%|████▏     | 18/43 [03:41<05:06, 12.26s/it] 44%|████▍     | 19/43 [03:53<04:54, 12.25s/it] 47%|████▋     | 20/43 [04:06<04:42, 12.27s/it] 49%|████▉     | 21/43 [04:18<04:30, 12.27s/it] 51%|█████     | 22/43 [04:30<04:17, 12.28s/it] 53%|█████▎    | 23/43 [04:42<04:05, 12.28s/it] 56%|█████▌    | 24/43 [04:56<03:59, 12.61s/it] 58%|█████▊    | 25/43 [05:08<03:45, 12.53s/it] 60%|██████    | 26/43 [05:20<03:31, 12.46s/it] 63%|██████▎   | 27/43 [05:33<03:18, 12.40s/it] 65%|██████▌   | 28/43 [05:45<03:05, 12.37s/it] 67%|██████▋   | 29/43 [05:57<02:52, 12.36s/it] 70%|██████▉   | 30/43 [06:10<02:40, 12.35s/it] 72%|███████▏  | 31/43 [06:22<02:28, 12.35s/it] 74%|███████▍  | 32/43 [06:34<02:15, 12.32s/it] 77%|███████▋  | 33/43 [06:47<02:03, 12.32s/it] 79%|███████▉  | 34/43 [06:59<01:50, 12.32s/it] 81%|████████▏ | 35/43 [07:11<01:38, 12.32s/it] 84%|████████▎ | 36/43 [07:25<01:28, 12.65s/it] 86%|████████▌ | 37/43 [07:37<01:15, 12.58s/it] 88%|████████▊ | 38/43 [07:50<01:02, 12.55s/it] 91%|█████████ | 39/43 [08:02<00:49, 12.47s/it] 93%|█████████▎| 40/43 [08:14<00:37, 12.43s/it] 95%|█████████▌| 41/43 [08:27<00:24, 12.41s/it] 98%|█████████▊| 42/43 [08:39<00:12, 12.41s/it]100%|██████████| 43/43 [08:51<00:00, 12.42s/it]100%|██████████| 43/43 [08:51<00:00, 12.37s/it]
Avg comparisons: 245.0
Avg prompt tokens: 101498.58139534884
Avg completion tokens: 0.0
Avg time per query: 12.368497693261435
