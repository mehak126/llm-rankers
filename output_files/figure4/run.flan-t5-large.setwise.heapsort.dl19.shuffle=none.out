/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]56it [00:00, 558.43it/s]1010it [00:00, 5834.72it/s]1595it [00:00, 4173.66it/s]2057it [00:00, 4303.31it/s]3014it [00:00, 5943.34it/s]3653it [00:00, 5210.46it/s]4216it [00:00, 4182.10it/s]5059it [00:01, 5165.38it/s]6021it [00:01, 6257.48it/s]6720it [00:01, 5687.98it/s]7346it [00:01, 5114.70it/s]8046it [00:01, 5547.70it/s]8645it [00:01, 5454.07it/s]9220it [00:01, 4608.32it/s]10048it [00:01, 5451.12it/s]11004it [00:02, 6474.45it/s]11706it [00:02, 5579.09it/s]12321it [00:02, 4621.42it/s]13050it [00:02, 5173.06it/s]14003it [00:02, 6200.33it/s]14695it [00:02, 5428.29it/s]15302it [00:02, 4498.87it/s]16060it [00:03, 5142.15it/s]17020it [00:03, 6171.90it/s]17716it [00:03, 5777.15it/s]18352it [00:03, 5247.90it/s]19049it [00:03, 5629.46it/s]19654it [00:03, 5513.14it/s]20234it [00:03, 4416.56it/s]21049it [00:04, 5254.09it/s]21637it [00:04, 5343.77it/s]22217it [00:04, 4686.99it/s]23055it [00:04, 5550.13it/s]24014it [00:04, 6537.90it/s]24720it [00:04, 5484.06it/s]25331it [00:04, 4799.07it/s]26059it [00:04, 5353.83it/s]27024it [00:05, 6374.18it/s]27724it [00:05, 6024.49it/s]28372it [00:05, 5027.03it/s]29051it [00:05, 5402.31it/s]30004it [00:05, 6408.71it/s]30702it [00:05, 5176.42it/s]31294it [00:05, 4613.81it/s]32059it [00:06, 5256.29it/s]33016it [00:06, 6245.87it/s]33710it [00:06, 5508.36it/s]34321it [00:06, 4714.95it/s]35061it [00:06, 5303.18it/s]36033it [00:06, 6334.22it/s]36734it [00:06, 6102.89it/s]37392it [00:06, 5198.29it/s]38062it [00:07, 5528.39it/s]39012it [00:07, 6491.31it/s]39712it [00:07, 5585.31it/s]40325it [00:07, 4654.16it/s]41053it [00:07, 5201.28it/s]42005it [00:07, 6208.22it/s]42694it [00:07, 5542.38it/s]43000it [00:07, 5424.91it/s]
  0%|          | 0/43 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors
  2%|▏         | 1/43 [00:04<03:27,  4.95s/it]  5%|▍         | 2/43 [00:09<03:16,  4.78s/it]  7%|▋         | 3/43 [00:14<03:08,  4.72s/it]  9%|▉         | 4/43 [00:18<03:03,  4.72s/it] 12%|█▏        | 5/43 [00:23<02:57,  4.68s/it] 14%|█▍        | 6/43 [00:28<02:52,  4.65s/it] 16%|█▋        | 7/43 [00:32<02:45,  4.59s/it] 19%|█▊        | 8/43 [00:37<02:38,  4.52s/it] 21%|██        | 9/43 [00:41<02:35,  4.58s/it] 23%|██▎       | 10/43 [00:46<02:33,  4.64s/it] 26%|██▌       | 11/43 [00:51<02:29,  4.68s/it] 28%|██▊       | 12/43 [00:55<02:23,  4.61s/it] 30%|███       | 13/43 [01:00<02:19,  4.66s/it] 33%|███▎      | 14/43 [01:05<02:14,  4.63s/it] 35%|███▍      | 15/43 [01:09<02:09,  4.62s/it] 37%|███▋      | 16/43 [01:14<02:03,  4.57s/it] 40%|███▉      | 17/43 [01:18<02:00,  4.63s/it] 42%|████▏     | 18/43 [01:23<01:56,  4.67s/it] 44%|████▍     | 19/43 [01:28<01:53,  4.75s/it] 47%|████▋     | 20/43 [01:33<01:48,  4.71s/it] 49%|████▉     | 21/43 [01:37<01:42,  4.66s/it] 51%|█████     | 22/43 [01:42<01:36,  4.58s/it] 53%|█████▎    | 23/43 [01:46<01:32,  4.61s/it] 56%|█████▌    | 24/43 [01:51<01:27,  4.61s/it] 58%|█████▊    | 25/43 [01:55<01:20,  4.47s/it] 60%|██████    | 26/43 [02:00<01:16,  4.51s/it] 63%|██████▎   | 27/43 [02:05<01:13,  4.61s/it] 65%|██████▌   | 28/43 [02:09<01:09,  4.64s/it] 67%|██████▋   | 29/43 [02:14<01:05,  4.70s/it] 70%|██████▉   | 30/43 [02:19<01:00,  4.63s/it] 72%|███████▏  | 31/43 [02:23<00:55,  4.60s/it] 74%|███████▍  | 32/43 [02:28<00:50,  4.63s/it] 77%|███████▋  | 33/43 [02:32<00:46,  4.65s/it] 79%|███████▉  | 34/43 [02:37<00:42,  4.75s/it] 81%|████████▏ | 35/43 [02:42<00:38,  4.78s/it] 84%|████████▎ | 36/43 [02:47<00:32,  4.68s/it] 86%|████████▌ | 37/43 [02:52<00:28,  4.75s/it] 88%|████████▊ | 38/43 [02:56<00:23,  4.73s/it] 91%|█████████ | 39/43 [03:01<00:18,  4.69s/it] 93%|█████████▎| 40/43 [03:05<00:13,  4.64s/it] 95%|█████████▌| 41/43 [03:10<00:09,  4.73s/it] 98%|█████████▊| 42/43 [03:15<00:04,  4.62s/it]100%|██████████| 43/43 [03:19<00:00,  4.55s/it]100%|██████████| 43/43 [03:19<00:00,  4.64s/it]
Avg comparisons: 58.23255813953488
Avg prompt tokens: 29440.558139534885
Avg completion tokens: 291.16279069767444
Avg time per query: 4.643223701521408
