/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.92s/it]
0it [00:00, ?it/s]58it [00:00, 568.56it/s]1015it [00:00, 5748.62it/s]1590it [00:00, 4416.87it/s]2060it [00:00, 4447.88it/s]3019it [00:00, 6057.87it/s]3656it [00:00, 5395.78it/s]4226it [00:00, 4383.52it/s]5059it [00:01, 5341.03it/s]6020it [00:01, 6434.02it/s]6728it [00:01, 5862.98it/s]7366it [00:01, 5191.07it/s]8051it [00:01, 5576.27it/s]9003it [00:01, 6557.93it/s]9706it [00:01, 5671.01it/s]10324it [00:01, 4807.42it/s]11059it [00:02, 5359.37it/s]12012it [00:02, 6335.70it/s]12706it [00:02, 5557.19it/s]13317it [00:02, 4728.34it/s]14053it [00:02, 5297.78it/s]15010it [00:02, 6306.55it/s]15706it [00:02, 5519.29it/s]16318it [00:03, 4870.78it/s]17058it [00:03, 5419.89it/s]18019it [00:03, 6421.21it/s]18721it [00:03, 6216.84it/s]19384it [00:03, 5135.09it/s]20054it [00:03, 5485.04it/s]21010it [00:03, 6462.05it/s]21710it [00:03, 5599.05it/s]22325it [00:04, 4990.65it/s]23059it [00:04, 5517.03it/s]24018it [00:04, 6503.28it/s]24722it [00:04, 5734.65it/s]25346it [00:04, 4995.06it/s]26060it [00:04, 5481.36it/s]27024it [00:04, 6495.85it/s]27729it [00:04, 6149.97it/s]28385it [00:05, 5242.55it/s]29054it [00:05, 5566.48it/s]30009it [00:05, 6538.03it/s]30710it [00:05, 5517.41it/s]31318it [00:05, 4879.15it/s]32059it [00:05, 5446.94it/s]33017it [00:05, 6431.87it/s]33718it [00:06, 5765.44it/s]34344it [00:06, 4933.78it/s]35061it [00:06, 5429.59it/s]36033it [00:06, 6450.26it/s]36736it [00:06, 6257.97it/s]37402it [00:06, 5323.08it/s]38062it [00:06, 5618.03it/s]39015it [00:06, 6593.56it/s]39722it [00:07, 5822.53it/s]40351it [00:07, 4905.33it/s]41055it [00:07, 5379.80it/s]42010it [00:07, 6370.31it/s]42705it [00:07, 5752.56it/s]43000it [00:07, 5629.81it/s]
  0%|          | 0/43 [00:00<?, ?it/s]/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
  2%|▏         | 1/43 [01:30<1:03:33, 90.80s/it]  5%|▍         | 2/43 [02:35<51:37, 75.54s/it]    7%|▋         | 3/43 [04:07<55:21, 83.04s/it]  9%|▉         | 4/43 [05:44<57:32, 88.53s/it] 12%|█▏        | 5/43 [07:05<54:14, 85.64s/it] 14%|█▍        | 6/43 [08:34<53:38, 86.99s/it] 16%|█▋        | 7/43 [09:58<51:39, 86.11s/it] 19%|█▊        | 8/43 [11:29<51:08, 87.66s/it] 21%|██        | 9/43 [12:33<45:22, 80.08s/it] 23%|██▎       | 10/43 [14:12<47:14, 85.88s/it] 26%|██▌       | 11/43 [15:34<45:16, 84.88s/it] 28%|██▊       | 12/43 [17:07<45:07, 87.33s/it] 30%|███       | 13/43 [18:27<42:28, 84.94s/it] 33%|███▎      | 14/43 [19:52<41:04, 84.99s/it] 35%|███▍      | 15/43 [21:24<40:41, 87.18s/it] 37%|███▋      | 16/43 [22:33<36:46, 81.73s/it] 40%|███▉      | 17/43 [24:01<36:09, 83.43s/it] 42%|████▏     | 18/43 [25:26<34:59, 84.00s/it] 44%|████▍     | 19/43 [26:58<34:35, 86.50s/it] 47%|████▋     | 20/43 [28:27<33:23, 87.12s/it] 49%|████▉     | 21/43 [29:52<31:44, 86.58s/it] 51%|█████     | 22/43 [31:00<28:23, 81.12s/it] 53%|█████▎    | 23/43 [32:36<28:26, 85.33s/it] 56%|█████▌    | 24/43 [34:00<26:54, 84.99s/it] 58%|█████▊    | 25/43 [35:03<23:34, 78.58s/it] 60%|██████    | 26/43 [36:34<23:15, 82.08s/it] 63%|██████▎   | 27/43 [38:01<22:17, 83.57s/it] 65%|██████▌   | 28/43 [39:29<21:13, 84.91s/it] 67%|██████▋   | 29/43 [40:45<19:12, 82.33s/it] 70%|██████▉   | 30/43 [42:03<17:31, 80.89s/it] 72%|███████▏  | 31/43 [43:11<15:25, 77.14s/it] 74%|███████▍  | 32/43 [44:39<14:45, 80.48s/it] 77%|███████▋  | 33/43 [46:06<13:42, 82.27s/it] 79%|███████▉  | 34/43 [47:16<11:49, 78.79s/it] 81%|████████▏ | 35/43 [48:34<10:27, 78.40s/it] 84%|████████▎ | 36/43 [50:08<09:41, 83.13s/it] 86%|████████▌ | 37/43 [51:31<08:18, 83.15s/it] 88%|████████▊ | 38/43 [53:01<07:05, 85.02s/it] 91%|█████████ | 39/43 [54:21<05:34, 83.58s/it] 93%|█████████▎| 40/43 [55:42<04:08, 82.78s/it] 95%|█████████▌| 41/43 [56:53<02:38, 79.32s/it] 98%|█████████▊| 42/43 [58:16<01:20, 80.55s/it]100%|██████████| 43/43 [59:52<00:00, 84.92s/it]100%|██████████| 43/43 [59:52<00:00, 83.54s/it]
Avg comparisons: 245.0
Avg prompt tokens: 119174.74418604652
Avg completion tokens: 2911.3488372093025
Avg time per query: 83.53592903669491
