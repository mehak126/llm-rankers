/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.54s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:04,  1.44s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:04<00:02,  1.44s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:05<00:01,  1.46s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.35s/it]
0it [00:00, ?it/s]59it [00:00, 584.12it/s]1017it [00:00, 5796.60it/s]1596it [00:00, 4564.27it/s]2077it [00:00, 4236.26it/s]3038it [00:00, 5855.21it/s]3661it [00:00, 5827.74it/s]4268it [00:00, 4738.37it/s]5061it [00:00, 5541.43it/s]6024it [00:01, 6619.34it/s]6739it [00:01, 6166.86it/s]7396it [00:01, 5538.21it/s]8053it [00:01, 5774.76it/s]9007it [00:01, 6734.52it/s]9715it [00:01, 5955.22it/s]10348it [00:01, 5068.23it/s]11063it [00:02, 5540.49it/s]12017it [00:02, 6517.50it/s]12719it [00:02, 5887.09it/s]13352it [00:02, 5030.69it/s]14058it [00:02, 5492.25it/s]15017it [00:02, 6477.08it/s]15718it [00:02, 5854.96it/s]16349it [00:02, 5173.11it/s]17060it [00:03, 5607.65it/s]18024it [00:03, 6600.22it/s]18731it [00:03, 6558.23it/s]19420it [00:03, 5449.12it/s]20056it [00:03, 5654.11it/s]21013it [00:03, 6644.02it/s]21724it [00:03, 5872.47it/s]22357it [00:03, 5248.46it/s]23061it [00:04, 5650.35it/s]24022it [00:04, 6627.86it/s]24729it [00:04, 6018.12it/s]25370it [00:04, 5262.73it/s]26062it [00:04, 5650.33it/s]27028it [00:04, 6654.72it/s]27739it [00:04, 6477.19it/s]28418it [00:04, 5537.04it/s]29056it [00:05, 5720.38it/s]30013it [00:05, 6694.46it/s]30722it [00:05, 5798.98it/s]31348it [00:05, 5141.39it/s]32061it [00:05, 5593.66it/s]33020it [00:05, 6592.65it/s]33728it [00:05, 6042.16it/s]34373it [00:05, 5201.85it/s]35064it [00:06, 5596.15it/s]36038it [00:06, 6602.37it/s]36746it [00:06, 6596.71it/s]37439it [00:06, 5683.29it/s]38064it [00:06, 5808.62it/s]39020it [00:06, 6754.22it/s]39732it [00:06, 6142.28it/s]40380it [00:06, 5181.70it/s]41059it [00:07, 5534.61it/s]42017it [00:07, 6530.16it/s]42718it [00:07, 6113.12it/s]43000it [00:07, 5861.86it/s]
  0%|          | 0/43 [00:00<?, ?it/s]/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
  2%|▏         | 1/43 [02:32<1:46:25, 152.03s/it]  5%|▍         | 2/43 [04:47<1:37:14, 142.30s/it]  7%|▋         | 3/43 [07:32<1:41:37, 152.43s/it]  9%|▉         | 4/43 [10:10<1:40:40, 154.88s/it] 12%|█▏        | 5/43 [12:34<1:35:37, 150.97s/it] 14%|█▍        | 6/43 [15:08<1:33:38, 151.86s/it] 16%|█▋        | 7/43 [17:46<1:32:23, 153.99s/it] 19%|█▊        | 8/43 [20:23<1:30:20, 154.88s/it] 21%|██        | 9/43 [22:28<1:22:29, 145.56s/it] 23%|██▎       | 10/43 [25:19<1:24:20, 153.36s/it] 26%|██▌       | 11/43 [27:49<1:21:15, 152.37s/it] 28%|██▊       | 12/43 [30:26<1:19:28, 153.81s/it] 30%|███       | 13/43 [32:37<1:13:27, 146.90s/it] 33%|███▎      | 14/43 [35:03<1:10:55, 146.73s/it] 35%|███▍      | 15/43 [37:37<1:09:26, 148.79s/it] 37%|███▋      | 16/43 [39:41<1:03:39, 141.47s/it] 40%|███▉      | 17/43 [42:11<1:02:19, 143.82s/it] 42%|████▏     | 18/43 [44:38<1:00:21, 144.87s/it] 44%|████▍     | 19/43 [46:59<57:29, 143.75s/it]   47%|████▋     | 20/43 [49:47<57:53, 151.00s/it] 49%|████▉     | 21/43 [52:28<56:28, 154.02s/it] 51%|█████     | 22/43 [54:37<51:14, 146.41s/it] 53%|█████▎    | 23/43 [57:18<50:16, 150.83s/it] 56%|█████▌    | 24/43 [59:22<45:14, 142.85s/it] 58%|█████▊    | 25/43 [1:01:22<40:48, 136.01s/it] 60%|██████    | 26/43 [1:03:52<39:40, 140.05s/it] 63%|██████▎   | 27/43 [1:06:11<37:17, 139.86s/it] 65%|██████▌   | 28/43 [1:08:38<35:30, 142.07s/it] 67%|██████▋   | 29/43 [1:10:46<32:09, 137.81s/it] 70%|██████▉   | 30/43 [1:13:05<29:53, 137.98s/it] 72%|███████▏  | 31/43 [1:15:12<26:59, 134.93s/it] 74%|███████▍  | 32/43 [1:17:43<25:34, 139.48s/it] 77%|███████▋  | 33/43 [1:20:01<23:13, 139.32s/it] 79%|███████▉  | 34/43 [1:22:00<19:56, 132.99s/it] 81%|████████▏ | 35/43 [1:24:16<17:52, 134.10s/it] 84%|████████▎ | 36/43 [1:27:05<16:52, 144.58s/it] 86%|████████▌ | 37/43 [1:29:25<14:19, 143.20s/it] 88%|████████▊ | 38/43 [1:32:01<12:14, 146.91s/it] 91%|█████████ | 39/43 [1:34:23<09:42, 145.51s/it] 93%|█████████▎| 40/43 [1:36:57<07:23, 147.86s/it] 95%|█████████▌| 41/43 [1:39:15<04:50, 145.09s/it] 98%|█████████▊| 42/43 [1:41:33<02:22, 142.97s/it]100%|██████████| 43/43 [1:44:29<00:00, 152.97s/it]100%|██████████| 43/43 [1:44:29<00:00, 145.81s/it]
Avg comparisons: 343.0
Avg prompt tokens: 167056.2093023256
Avg completion tokens: 4031.2093023255816
Avg time per query: 145.81338672859724
