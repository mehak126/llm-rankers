/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]56it [00:00, 553.93it/s]1010it [00:00, 5774.08it/s]1588it [00:00, 4097.77it/s]2056it [00:00, 4271.13it/s]3014it [00:00, 5884.74it/s]3646it [00:00, 5145.55it/s]4202it [00:00, 4120.94it/s]5059it [00:01, 5134.87it/s]6020it [00:01, 6238.70it/s]6720it [00:01, 5636.99it/s]7344it [00:01, 5033.96it/s]8046it [00:01, 5474.85it/s]8640it [00:01, 5361.08it/s]9208it [00:01, 4560.93it/s]10046it [00:01, 5441.19it/s]11002it [00:02, 6449.37it/s]11702it [00:02, 5462.83it/s]12309it [00:02, 4537.37it/s]13046it [00:02, 5135.86it/s]13627it [00:02, 5267.96it/s]14204it [00:02, 4519.22it/s]15048it [00:02, 5407.44it/s]15650it [00:03, 5482.18it/s]16242it [00:03, 4756.58it/s]17056it [00:03, 5533.04it/s]18015it [00:03, 6558.27it/s]18724it [00:03, 6245.05it/s]19388it [00:03, 4997.95it/s]20052it [00:03, 5358.16it/s]21005it [00:03, 6366.92it/s]21703it [00:04, 5258.07it/s]22300it [00:04, 4713.39it/s]23054it [00:04, 5337.41it/s]24013it [00:04, 6340.65it/s]24713it [00:04, 5349.42it/s]25317it [00:04, 4705.10it/s]26058it [00:04, 5297.91it/s]27023it [00:05, 6326.38it/s]27724it [00:05, 5952.64it/s]28370it [00:05, 4960.56it/s]29050it [00:05, 5367.41it/s]30003it [00:05, 6362.32it/s]30699it [00:05, 5139.12it/s]31289it [00:05, 4590.04it/s]32059it [00:06, 5247.45it/s]33014it [00:06, 6263.39it/s]33713it [00:06, 5477.88it/s]34326it [00:06, 4681.58it/s]35061it [00:06, 5252.49it/s]36034it [00:06, 6299.66it/s]36735it [00:06, 6084.58it/s]37393it [00:07, 5168.43it/s]38062it [00:07, 5491.23it/s]39012it [00:07, 6467.17it/s]39712it [00:07, 5542.06it/s]40323it [00:07, 4600.47it/s]41053it [00:07, 5173.04it/s]42005it [00:07, 6181.82it/s]42695it [00:07, 5518.63it/s]43000it [00:07, 5400.62it/s]
  0%|          | 0/43 [00:00<?, ?it/s]  2%|▏         | 1/43 [00:25<17:56, 25.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors
  5%|▍         | 2/43 [00:50<17:16, 25.28s/it]  7%|▋         | 3/43 [01:15<16:49, 25.24s/it]  9%|▉         | 4/43 [01:42<16:47, 25.85s/it] 12%|█▏        | 5/43 [02:06<15:50, 25.02s/it] 14%|█▍        | 6/43 [02:32<15:47, 25.60s/it] 16%|█▋        | 7/43 [02:59<15:33, 25.93s/it] 19%|█▊        | 8/43 [03:26<15:14, 26.13s/it] 21%|██        | 9/43 [03:49<14:15, 25.17s/it] 23%|██▎       | 10/43 [04:14<13:48, 25.10s/it] 26%|██▌       | 11/43 [04:35<12:46, 23.95s/it] 28%|██▊       | 12/43 [05:01<12:39, 24.52s/it] 30%|███       | 13/43 [05:26<12:21, 24.71s/it] 33%|███▎      | 14/43 [05:52<12:10, 25.18s/it] 35%|███▍      | 15/43 [06:19<11:56, 25.59s/it] 37%|███▋      | 16/43 [06:41<11:05, 24.65s/it] 40%|███▉      | 17/43 [07:07<10:50, 25.00s/it] 42%|████▏     | 18/43 [07:31<10:17, 24.69s/it] 44%|████▍     | 19/43 [07:56<09:52, 24.70s/it] 47%|████▋     | 20/43 [08:21<09:29, 24.75s/it] 49%|████▉     | 21/43 [08:40<08:28, 23.14s/it] 51%|█████     | 22/43 [09:06<08:23, 23.98s/it] 53%|█████▎    | 23/43 [09:32<08:13, 24.69s/it] 56%|█████▌    | 24/43 [09:55<07:40, 24.25s/it] 58%|█████▊    | 25/43 [10:22<07:28, 24.94s/it] 60%|██████    | 26/43 [10:47<07:04, 24.98s/it] 63%|██████▎   | 27/43 [11:12<06:41, 25.12s/it] 65%|██████▌   | 28/43 [11:34<06:01, 24.07s/it] 67%|██████▋   | 29/43 [12:00<05:44, 24.61s/it] 70%|██████▉   | 30/43 [12:26<05:26, 25.11s/it] 72%|███████▏  | 31/43 [12:53<05:06, 25.54s/it] 74%|███████▍  | 32/43 [13:17<04:35, 25.04s/it] 77%|███████▋  | 33/43 [13:43<04:14, 25.49s/it] 79%|███████▉  | 34/43 [14:10<03:51, 25.75s/it] 81%|████████▏ | 35/43 [14:36<03:26, 25.84s/it] 84%|████████▎ | 36/43 [15:02<03:01, 26.00s/it] 86%|████████▌ | 37/43 [15:27<02:34, 25.73s/it] 88%|████████▊ | 38/43 [15:51<02:05, 25.16s/it] 91%|█████████ | 39/43 [16:17<01:42, 25.53s/it] 93%|█████████▎| 40/43 [16:44<01:17, 25.80s/it] 95%|█████████▌| 41/43 [17:08<00:50, 25.25s/it] 98%|█████████▊| 42/43 [17:34<00:25, 25.63s/it]100%|██████████| 43/43 [18:01<00:00, 25.88s/it]100%|██████████| 43/43 [18:01<00:00, 25.14s/it]
Avg comparisons: 300.8837209302326
Avg prompt tokens: 124257.90697674418
Avg completion tokens: 1504.4186046511627
Avg time per query: 25.144924490950828
