/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]58it [00:00, 570.79it/s]1014it [00:00, 5778.30it/s]1593it [00:00, 4268.30it/s]2058it [00:00, 4382.32it/s]3017it [00:00, 6018.52it/s]3658it [00:00, 5356.53it/s]4229it [00:00, 4304.53it/s]5060it [00:01, 5250.95it/s]6022it [00:01, 6360.73it/s]6728it [00:01, 5820.77it/s]7365it [00:01, 5245.06it/s]8046it [00:01, 5600.69it/s]8646it [00:01, 5504.84it/s]9223it [00:01, 4696.44it/s]10049it [00:01, 5539.19it/s]11006it [00:02, 6547.38it/s]11711it [00:02, 5734.96it/s]12335it [00:02, 4752.06it/s]13050it [00:02, 5275.11it/s]14002it [00:02, 6275.25it/s]14694it [00:02, 5489.60it/s]15303it [00:02, 4554.79it/s]16061it [00:03, 5192.79it/s]17022it [00:03, 6196.34it/s]17715it [00:03, 5880.32it/s]18356it [00:03, 5341.81it/s]19050it [00:03, 5717.22it/s]20001it [00:03, 6650.91it/s]20709it [00:03, 5565.51it/s]21322it [00:04, 4586.72it/s]22060it [00:04, 5180.60it/s]23022it [00:04, 6199.85it/s]23716it [00:04, 5871.52it/s]24356it [00:04, 4772.60it/s]25058it [00:04, 5263.41it/s]26014it [00:04, 6278.85it/s]26712it [00:04, 5986.72it/s]27361it [00:05, 5166.41it/s]28056it [00:05, 5581.85it/s]29008it [00:05, 6552.04it/s]29715it [00:05, 5560.65it/s]30330it [00:05, 4557.56it/s]31060it [00:05, 5135.19it/s]32019it [00:05, 6162.47it/s]32712it [00:05, 5874.12it/s]33354it [00:06, 4848.13it/s]34058it [00:06, 5320.55it/s]35013it [00:06, 6317.33it/s]35710it [00:06, 5974.42it/s]36355it [00:06, 5248.71it/s]37054it [00:06, 5657.94it/s]38018it [00:06, 6649.29it/s]38731it [00:07, 5967.23it/s]39372it [00:07, 4971.33it/s]40045it [00:07, 5358.35it/s]41006it [00:07, 6382.82it/s]41702it [00:07, 5424.73it/s]42306it [00:07, 4834.95it/s]43000it [00:07, 5538.69it/s]
  0%|          | 0/43 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors
  2%|▏         | 1/43 [00:19<13:37, 19.46s/it]  5%|▍         | 2/43 [00:36<12:16, 17.96s/it]  7%|▋         | 3/43 [00:55<12:16, 18.40s/it]  9%|▉         | 4/43 [01:12<11:33, 17.79s/it] 12%|█▏        | 5/43 [01:28<10:59, 17.37s/it] 14%|█▍        | 6/43 [01:46<10:49, 17.56s/it] 16%|█▋        | 7/43 [02:03<10:22, 17.29s/it] 19%|█▊        | 8/43 [02:22<10:25, 17.86s/it] 21%|██        | 9/43 [02:39<09:58, 17.61s/it] 23%|██▎       | 10/43 [02:53<09:05, 16.54s/it] 26%|██▌       | 11/43 [03:09<08:46, 16.45s/it] 28%|██▊       | 12/43 [03:21<07:46, 15.03s/it] 30%|███       | 13/43 [03:40<08:08, 16.29s/it] 33%|███▎      | 14/43 [03:59<08:12, 16.97s/it] 35%|███▍      | 15/43 [04:11<07:10, 15.38s/it] 37%|███▋      | 16/43 [04:29<07:20, 16.31s/it] 40%|███▉      | 17/43 [04:48<07:20, 16.93s/it] 42%|████▏     | 18/43 [05:04<06:58, 16.72s/it] 44%|████▍     | 19/43 [05:22<06:53, 17.24s/it] 47%|████▋     | 20/43 [05:38<06:23, 16.68s/it] 49%|████▉     | 21/43 [05:55<06:09, 16.78s/it] 51%|█████     | 22/43 [06:11<05:50, 16.67s/it] 53%|█████▎    | 23/43 [06:22<04:56, 14.83s/it] 56%|█████▌    | 24/43 [06:41<05:05, 16.10s/it] 58%|█████▊    | 25/43 [07:00<05:05, 17.00s/it] 60%|██████    | 26/43 [07:19<04:59, 17.62s/it] 63%|██████▎   | 27/43 [07:37<04:46, 17.89s/it] 65%|██████▌   | 28/43 [07:55<04:28, 17.91s/it] 67%|██████▋   | 29/43 [08:15<04:16, 18.31s/it] 70%|██████▉   | 30/43 [08:35<04:04, 18.83s/it] 72%|███████▏  | 31/43 [08:53<03:44, 18.72s/it] 74%|███████▍  | 32/43 [09:12<03:25, 18.66s/it] 77%|███████▋  | 33/43 [09:28<03:01, 18.12s/it] 79%|███████▉  | 34/43 [09:47<02:44, 18.24s/it] 81%|████████▏ | 35/43 [10:04<02:23, 17.99s/it] 84%|████████▎ | 36/43 [10:23<02:08, 18.32s/it] 86%|████████▌ | 37/43 [10:41<01:48, 18.00s/it] 88%|████████▊ | 38/43 [10:59<01:30, 18.19s/it] 91%|█████████ | 39/43 [11:18<01:13, 18.39s/it] 93%|█████████▎| 40/43 [11:37<00:55, 18.56s/it] 95%|█████████▌| 41/43 [11:56<00:37, 18.74s/it] 98%|█████████▊| 42/43 [12:14<00:18, 18.55s/it]100%|██████████| 43/43 [12:29<00:00, 17.24s/it]100%|██████████| 43/43 [12:29<00:00, 17.42s/it]
Avg comparisons: 218.02325581395348
Avg prompt tokens: 110005.90697674418
Avg completion tokens: 1090.1162790697674
Avg time per query: 17.419237707936485
