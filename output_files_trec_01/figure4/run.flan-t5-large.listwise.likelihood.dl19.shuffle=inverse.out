/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]57it [00:00, 569.12it/s]1012it [00:00, 5787.76it/s]1588it [00:00, 4194.67it/s]2058it [00:00, 4334.46it/s]3017it [00:00, 5954.13it/s]3652it [00:00, 5279.19it/s]4216it [00:00, 4223.15it/s]5059it [00:01, 5203.28it/s]6021it [00:01, 6290.38it/s]6721it [00:01, 5709.83it/s]7348it [00:01, 5124.62it/s]8046it [00:01, 5552.97it/s]8644it [00:01, 5450.29it/s]9218it [00:01, 4631.32it/s]10048it [00:01, 5490.32it/s]11004it [00:02, 6508.69it/s]11709it [00:02, 5588.79it/s]12325it [00:02, 4624.82it/s]13050it [00:02, 5171.34it/s]14003it [00:02, 6198.39it/s]14695it [00:02, 5443.01it/s]15303it [00:02, 4512.96it/s]16060it [00:03, 5154.63it/s]17020it [00:03, 6183.00it/s]17717it [00:03, 5774.42it/s]18352it [00:03, 5248.78it/s]19050it [00:03, 5635.98it/s]20001it [00:03, 6576.83it/s]20704it [00:03, 5493.79it/s]21312it [00:04, 4517.05it/s]22059it [00:04, 5138.60it/s]23020it [00:04, 6171.83it/s]23715it [00:04, 5793.84it/s]24351it [00:04, 4713.26it/s]25058it [00:04, 5209.56it/s]26014it [00:04, 6238.24it/s]26711it [00:04, 5942.31it/s]27357it [00:05, 5112.84it/s]28056it [00:05, 5531.77it/s]29007it [00:05, 6498.33it/s]29710it [00:05, 5478.01it/s]30319it [00:05, 4474.01it/s]31059it [00:05, 5080.44it/s]32017it [00:05, 6111.78it/s]32708it [00:06, 5760.84it/s]33342it [00:06, 4760.43it/s]34057it [00:06, 5275.31it/s]35011it [00:06, 6280.99it/s]35709it [00:06, 5875.25it/s]36348it [00:06, 5148.96it/s]37054it [00:06, 5572.73it/s]38018it [00:06, 6569.03it/s]38726it [00:07, 5885.81it/s]39360it [00:07, 4874.84it/s]40045it [00:07, 5293.40it/s]41005it [00:07, 6320.17it/s]41698it [00:07, 5347.54it/s]42297it [00:07, 4749.27it/s]43000it [00:07, 5467.89it/s]
  0%|          | 0/43 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors
  2%|▏         | 1/43 [00:12<08:35, 12.28s/it]  5%|▍         | 2/43 [00:24<08:15, 12.08s/it]  7%|▋         | 3/43 [00:36<08:00, 12.01s/it]  9%|▉         | 4/43 [00:48<07:46, 11.96s/it] 12%|█▏        | 5/43 [00:59<07:34, 11.96s/it] 14%|█▍        | 6/43 [01:11<07:21, 11.92s/it] 16%|█▋        | 7/43 [01:23<07:08, 11.91s/it] 19%|█▊        | 8/43 [01:35<06:56, 11.89s/it] 21%|██        | 9/43 [01:47<06:44, 11.90s/it] 23%|██▎       | 10/43 [01:59<06:31, 11.87s/it] 26%|██▌       | 11/43 [02:11<06:19, 11.85s/it] 28%|██▊       | 12/43 [02:22<06:06, 11.84s/it] 30%|███       | 13/43 [02:34<05:54, 11.83s/it] 33%|███▎      | 14/43 [02:46<05:43, 11.83s/it] 35%|███▍      | 15/43 [02:58<05:31, 11.85s/it] 37%|███▋      | 16/43 [03:10<05:20, 11.87s/it] 40%|███▉      | 17/43 [03:22<05:08, 11.85s/it] 42%|████▏     | 18/43 [03:33<04:55, 11.83s/it] 44%|████▍     | 19/43 [03:45<04:43, 11.81s/it] 47%|████▋     | 20/43 [03:57<04:31, 11.81s/it] 49%|████▉     | 21/43 [04:09<04:19, 11.82s/it] 51%|█████     | 22/43 [04:21<04:08, 11.84s/it] 53%|█████▎    | 23/43 [04:33<03:56, 11.84s/it] 56%|█████▌    | 24/43 [04:44<03:44, 11.84s/it] 58%|█████▊    | 25/43 [04:56<03:33, 11.84s/it] 60%|██████    | 26/43 [05:08<03:21, 11.84s/it] 63%|██████▎   | 27/43 [05:20<03:09, 11.83s/it] 65%|██████▌   | 28/43 [05:32<02:57, 11.83s/it] 67%|██████▋   | 29/43 [05:44<02:45, 11.82s/it] 70%|██████▉   | 30/43 [05:55<02:33, 11.84s/it] 72%|███████▏  | 31/43 [06:07<02:22, 11.84s/it] 74%|███████▍  | 32/43 [06:19<02:10, 11.85s/it] 77%|███████▋  | 33/43 [06:31<01:58, 11.85s/it] 79%|███████▉  | 34/43 [06:43<01:46, 11.86s/it] 81%|████████▏ | 35/43 [06:55<01:34, 11.87s/it] 84%|████████▎ | 36/43 [07:07<01:23, 11.87s/it] 86%|████████▌ | 37/43 [07:18<01:10, 11.83s/it] 88%|████████▊ | 38/43 [07:30<00:59, 11.84s/it] 91%|█████████ | 39/43 [07:42<00:47, 11.82s/it] 93%|█████████▎| 40/43 [07:54<00:35, 11.83s/it] 95%|█████████▌| 41/43 [08:06<00:23, 11.85s/it] 98%|█████████▊| 42/43 [08:18<00:11, 11.85s/it]100%|██████████| 43/43 [08:29<00:00, 11.84s/it]100%|██████████| 43/43 [08:29<00:00, 11.86s/it]
Avg comparisons: 245.0
Avg prompt tokens: 102463.16279069768
Avg completion tokens: 0.0
Avg time per query: 11.858754002770713
