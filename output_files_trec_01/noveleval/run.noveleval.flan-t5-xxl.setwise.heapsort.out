/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:07,  1.94s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:03<00:05,  1.88s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:05<00:03,  1.90s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:07<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:09<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:09<00:00,  1.81s/it]
0it [00:00, ?it/s]27it [00:00, 266.48it/s]60it [00:00, 299.30it/s]95it [00:00, 320.77it/s]171it [00:00, 489.38it/s]220it [00:00, 426.50it/s]264it [00:00, 399.98it/s]305it [00:00, 386.90it/s]493it [00:00, 810.87it/s]580it [00:01, 629.43it/s]692it [00:01, 743.61it/s]777it [00:01, 654.73it/s]961it [00:01, 928.85it/s]1068it [00:01, 819.75it/s]1166it [00:01, 853.72it/s]1260it [00:01, 758.04it/s]1409it [00:02, 927.16it/s]1512it [00:02, 700.56it/s]1597it [00:02, 600.89it/s]1749it [00:02, 779.01it/s]1844it [00:02, 707.43it/s]1967it [00:02, 818.09it/s]2062it [00:03, 724.01it/s]2145it [00:03, 707.75it/s]2223it [00:03, 648.11it/s]2293it [00:03, 541.41it/s]2465it [00:03, 785.88it/s]2558it [00:03, 509.88it/s]2632it [00:04, 545.28it/s]2704it [00:04, 432.26it/s]2813it [00:04, 544.94it/s]2887it [00:04, 423.53it/s]2959it [00:04, 470.92it/s]3022it [00:05, 388.75it/s]3074it [00:05, 390.36it/s]3188it [00:05, 533.55it/s]3256it [00:05, 435.93it/s]3377it [00:05, 584.13it/s]3453it [00:05, 513.82it/s]3518it [00:05, 497.22it/s]3577it [00:06, 488.71it/s]3813it [00:06, 901.32it/s]3922it [00:06, 814.91it/s]3966it [00:06, 622.58it/s]
  0%|          | 0/21 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors
  5%|▍         | 1/21 [00:14<04:56, 14.81s/it] 10%|▉         | 2/21 [00:28<04:26, 14.02s/it] 14%|█▍        | 3/21 [00:41<04:07, 13.78s/it] 19%|█▉        | 4/21 [00:55<03:55, 13.86s/it] 24%|██▍       | 5/21 [01:11<03:51, 14.47s/it] 29%|██▊       | 6/21 [01:26<03:39, 14.63s/it] 33%|███▎      | 7/21 [01:40<03:23, 14.53s/it] 38%|███▊      | 8/21 [01:54<03:06, 14.35s/it] 43%|████▎     | 9/21 [02:09<02:54, 14.54s/it] 48%|████▊     | 10/21 [02:23<02:38, 14.42s/it] 52%|█████▏    | 11/21 [02:37<02:22, 14.29s/it] 57%|█████▋    | 12/21 [02:51<02:07, 14.13s/it] 62%|██████▏   | 13/21 [03:06<01:56, 14.54s/it] 67%|██████▋   | 14/21 [03:20<01:39, 14.23s/it] 71%|███████▏  | 15/21 [03:34<01:25, 14.31s/it] 76%|███████▌  | 16/21 [03:49<01:12, 14.48s/it] 81%|████████  | 17/21 [04:03<00:57, 14.37s/it] 86%|████████▌ | 18/21 [04:18<00:43, 14.46s/it] 90%|█████████ | 19/21 [04:32<00:28, 14.42s/it] 95%|█████████▌| 20/21 [04:46<00:14, 14.22s/it]100%|██████████| 21/21 [05:00<00:00, 14.23s/it]100%|██████████| 21/21 [05:00<00:00, 14.33s/it]
Avg comparisons: 72.85714285714286
Avg prompt tokens: 41988.619047619046
Avg completion tokens: 364.2857142857143
Avg time per query: 14.327646096547445
