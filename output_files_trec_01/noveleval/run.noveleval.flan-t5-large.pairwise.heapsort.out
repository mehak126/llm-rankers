/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]27it [00:00, 264.82it/s]60it [00:00, 300.13it/s]95it [00:00, 322.05it/s]171it [00:00, 492.42it/s]221it [00:00, 431.17it/s]266it [00:00, 403.42it/s]308it [00:00, 389.92it/s]497it [00:00, 811.40it/s]584it [00:01, 650.43it/s]692it [00:01, 752.02it/s]776it [00:01, 658.54it/s]961it [00:01, 939.82it/s]1068it [00:01, 827.82it/s]1166it [00:01, 862.96it/s]1261it [00:01, 769.16it/s]1409it [00:01, 938.03it/s]1513it [00:02, 706.38it/s]1599it [00:02, 617.16it/s]1749it [00:02, 793.38it/s]1845it [00:02, 712.79it/s]1968it [00:02, 819.39it/s]2063it [00:02, 730.47it/s]2146it [00:03, 712.39it/s]2224it [00:03, 652.04it/s]2295it [00:03, 557.09it/s]2475it [00:03, 820.02it/s]2571it [00:03, 635.45it/s]2665it [00:03, 695.59it/s]2748it [00:04, 636.80it/s]2846it [00:04, 711.35it/s]2927it [00:04, 628.06it/s]2998it [00:04, 623.31it/s]3066it [00:04, 567.51it/s]3200it [00:04, 746.08it/s]3283it [00:04, 653.68it/s]3389it [00:04, 743.98it/s]3471it [00:05, 639.05it/s]3543it [00:05, 544.18it/s]3791it [00:05, 955.88it/s]3908it [00:05, 784.25it/s]3966it [00:05, 702.44it/s]
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:16<05:29, 16.46s/it] 10%|▉         | 2/21 [00:32<05:07, 16.20s/it] 14%|█▍        | 3/21 [00:52<05:22, 17.93s/it] 19%|█▉        | 4/21 [01:09<05:01, 17.73s/it] 24%|██▍       | 5/21 [01:26<04:38, 17.39s/it] 29%|██▊       | 6/21 [01:43<04:19, 17.30s/it] 33%|███▎      | 7/21 [02:02<04:06, 17.60s/it] 38%|███▊      | 8/21 [02:20<03:54, 18.02s/it] 43%|████▎     | 9/21 [02:39<03:39, 18.30s/it] 48%|████▊     | 10/21 [02:57<03:20, 18.23s/it] 52%|█████▏    | 11/21 [03:15<02:59, 17.91s/it] 57%|█████▋    | 12/21 [03:33<02:43, 18.13s/it] 62%|██████▏   | 13/21 [03:51<02:24, 18.06s/it] 67%|██████▋   | 14/21 [04:07<02:00, 17.25s/it] 71%|███████▏  | 15/21 [04:25<01:46, 17.73s/it] 76%|███████▌  | 16/21 [04:44<01:29, 17.92s/it] 81%|████████  | 17/21 [05:02<01:12, 18.16s/it] 86%|████████▌ | 18/21 [05:19<00:53, 17.73s/it] 90%|█████████ | 19/21 [05:37<00:35, 17.68s/it] 95%|█████████▌| 20/21 [05:55<00:17, 17.86s/it]100%|██████████| 21/21 [06:13<00:00, 17.78s/it]100%|██████████| 21/21 [06:13<00:00, 17.77s/it]
Avg comparisons: 211.57142857142858
Avg prompt tokens: 130628.47619047618
Avg completion tokens: 2115.714285714286
Avg time per query: 17.767143578756425
