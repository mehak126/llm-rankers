/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0it [00:00, ?it/s]26it [00:00, 256.03it/s]58it [00:00, 289.16it/s]92it [00:00, 308.89it/s]168it [00:00, 479.53it/s]216it [00:00, 421.62it/s]260it [00:00, 393.22it/s]301it [00:00, 380.39it/s]490it [00:00, 804.99it/s]576it [00:01, 614.26it/s]691it [00:01, 739.76it/s]776it [00:01, 650.24it/s]959it [00:01, 924.51it/s]1066it [00:01, 799.16it/s]1166it [00:01, 843.68it/s]1261it [00:01, 755.68it/s]1409it [00:02, 921.91it/s]1512it [00:02, 700.94it/s]1597it [00:02, 608.44it/s]1749it [00:02, 787.66it/s]1845it [00:02, 716.90it/s]1967it [00:02, 824.63it/s]2063it [00:03, 725.48it/s]2146it [00:03, 706.95it/s]2224it [00:03, 634.10it/s]2293it [00:03, 535.58it/s]2472it [00:03, 797.84it/s]2567it [00:03, 636.03it/s]2666it [00:03, 705.06it/s]2751it [00:04, 633.07it/s]2847it [00:04, 701.26it/s]2928it [00:04, 627.98it/s]2999it [00:04, 618.04it/s]3067it [00:04, 564.92it/s]3200it [00:04, 739.52it/s]3282it [00:04, 646.06it/s]3388it [00:05, 740.91it/s]3470it [00:05, 635.25it/s]3541it [00:05, 540.29it/s]3789it [00:05, 950.66it/s]3906it [00:05, 774.93it/s]3966it [00:05, 694.13it/s]
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:25<08:27, 25.37s/it] 10%|▉         | 2/21 [01:25<14:25, 45.53s/it] 14%|█▍        | 3/21 [02:41<17:51, 59.53s/it] 19%|█▉        | 4/21 [03:43<17:13, 60.79s/it] 24%|██▍       | 5/21 [04:23<14:07, 52.96s/it] 29%|██▊       | 6/21 [05:01<11:59, 47.99s/it] 33%|███▎      | 7/21 [05:58<11:51, 50.83s/it] 38%|███▊      | 8/21 [07:04<12:05, 55.80s/it] 43%|████▎     | 9/21 [08:08<11:42, 58.51s/it] 48%|████▊     | 10/21 [09:16<11:15, 61.45s/it] 52%|█████▏    | 11/21 [10:18<10:13, 61.33s/it] 57%|█████▋    | 12/21 [11:28<09:36, 64.04s/it] 62%|██████▏   | 13/21 [12:18<07:58, 59.82s/it] 67%|██████▋   | 14/21 [12:40<05:39, 48.50s/it] 71%|███████▏  | 15/21 [13:56<05:40, 56.81s/it] 76%|███████▌  | 16/21 [14:48<04:36, 55.23s/it] 81%|████████  | 17/21 [16:05<04:07, 61.85s/it] 86%|████████▌ | 18/21 [16:38<02:39, 53.29s/it] 90%|█████████ | 19/21 [17:36<01:49, 54.54s/it] 95%|█████████▌| 20/21 [18:47<00:59, 59.44s/it]100%|██████████| 21/21 [19:46<00:00, 59.28s/it]100%|██████████| 21/21 [19:46<00:00, 56.48s/it]
Avg comparisons: 658.7142857142857
Avg prompt tokens: 406968.6666666667
Avg completion tokens: 6587.142857142857
Avg time per query: 56.484589996792025
