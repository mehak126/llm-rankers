/home/mdhaliwal/miniconda3/envs/llmrankers/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:07,  1.92s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:03<00:05,  1.82s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:05<00:03,  1.83s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:07<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:08<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:08<00:00,  1.76s/it]
0it [00:00, ?it/s]27it [00:00, 266.61it/s]60it [00:00, 299.23it/s]94it [00:00, 316.60it/s]169it [00:00, 485.45it/s]218it [00:00, 424.93it/s]262it [00:00, 399.51it/s]303it [00:00, 385.49it/s]492it [00:00, 811.57it/s]579it [00:01, 628.53it/s]692it [00:01, 747.13it/s]777it [00:01, 658.23it/s]961it [00:01, 934.29it/s]1068it [00:01, 825.64it/s]1166it [00:01, 860.04it/s]1261it [00:01, 766.34it/s]1409it [00:01, 934.12it/s]1513it [00:02, 702.17it/s]1598it [00:02, 612.13it/s]1749it [00:02, 789.76it/s]1845it [00:02, 717.48it/s]1967it [00:02, 825.07it/s]2063it [00:02, 733.09it/s]2147it [00:03, 708.85it/s]2225it [00:03, 648.13it/s]2295it [00:03, 553.67it/s]2474it [00:03, 817.98it/s]2570it [00:03, 653.53it/s]2666it [00:03, 713.96it/s]2751it [00:04, 639.02it/s]2847it [00:04, 705.62it/s]2927it [00:04, 630.98it/s]2998it [00:04, 625.63it/s]3066it [00:04, 569.17it/s]3200it [00:04, 747.19it/s]3283it [00:04, 653.14it/s]3388it [00:04, 744.69it/s]3471it [00:05, 635.52it/s]3543it [00:05, 541.17it/s]3791it [00:05, 950.04it/s]3908it [00:05, 782.48it/s]3966it [00:05, 701.48it/s]
  0%|          | 0/21 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors
  5%|▍         | 1/21 [01:02<20:48, 62.42s/it] 10%|▉         | 2/21 [01:47<16:29, 52.09s/it] 14%|█▍        | 3/21 [02:50<17:09, 57.18s/it] 19%|█▉        | 4/21 [03:53<16:51, 59.48s/it] 24%|██▍       | 5/21 [04:56<16:10, 60.68s/it] 29%|██▊       | 6/21 [05:58<15:16, 61.13s/it] 33%|███▎      | 7/21 [06:57<14:08, 60.60s/it] 38%|███▊      | 8/21 [08:01<13:18, 61.44s/it] 43%|████▎     | 9/21 [09:04<12:22, 61.91s/it] 48%|████▊     | 10/21 [10:01<11:05, 60.47s/it] 52%|█████▏    | 11/21 [10:56<09:48, 58.87s/it] 57%|█████▋    | 12/21 [11:58<08:57, 59.67s/it] 62%|██████▏   | 13/21 [12:56<07:54, 59.37s/it] 67%|██████▋   | 14/21 [13:59<07:02, 60.33s/it] 71%|███████▏  | 15/21 [14:57<05:58, 59.74s/it] 76%|███████▌  | 16/21 [15:55<04:55, 59.15s/it] 81%|████████  | 17/21 [16:58<04:01, 60.27s/it] 86%|████████▌ | 18/21 [17:55<02:58, 59.50s/it] 90%|█████████ | 19/21 [18:55<01:58, 59.41s/it] 95%|█████████▌| 20/21 [19:55<00:59, 59.66s/it]100%|██████████| 21/21 [20:50<00:00, 58.33s/it]100%|██████████| 21/21 [20:50<00:00, 59.55s/it]
Avg comparisons: 302.76190476190476
Avg prompt tokens: 173491.14285714287
Avg completion tokens: 1513.8095238095239
Avg time per query: 59.55423854646229
