Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]
/home/mdhaliwal/miniconda3/envs/test-llmrankers/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/mdhaliwal/miniconda3/envs/test-llmrankers/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/mdhaliwal/miniconda3/envs/test-llmrankers/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/mdhaliwal/miniconda3/envs/test-llmrankers/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
0it [00:00, ?it/s]2078it [00:00, 20755.43it/s]5063it [00:00, 26100.02it/s]8055it [00:00, 27827.35it/s]11054it [00:00, 28657.36it/s]14047it [00:00, 29096.82it/s]17058it [00:00, 29425.31it/s]20056it [00:00, 29601.79it/s]23049it [00:00, 29678.11it/s]26044it [00:00, 29760.76it/s]29043it [00:01, 29805.06it/s]32035it [00:01, 29826.01it/s]35034it [00:01, 29849.53it/s]38040it [00:01, 29912.52it/s]41032it [00:01, 29601.95it/s]43000it [00:01, 29389.01it/s]
  0%|          | 0/43 [00:00<?, ?it/s]/home/mdhaliwal/miniconda3/envs/test-llmrankers/lib/python3.9/site-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )
  warnings.warn(
  2%|▏         | 1/43 [06:46<4:44:34, 406.54s/it]  5%|▍         | 2/43 [13:35<4:38:52, 408.12s/it]  7%|▋         | 3/43 [20:22<4:31:48, 407.70s/it]  9%|▉         | 4/43 [27:13<4:25:39, 408.70s/it] 12%|█▏        | 5/43 [34:06<4:19:56, 410.43s/it] 14%|█▍        | 6/43 [40:49<4:11:25, 407.71s/it] 16%|█▋        | 7/43 [47:39<4:05:06, 408.52s/it] 19%|█▊        | 8/43 [54:25<3:57:53, 407.81s/it] 21%|██        | 9/43 [1:01:17<3:51:45, 408.98s/it] 23%|██▎       | 10/43 [1:08:03<3:44:28, 408.13s/it] 26%|██▌       | 11/43 [1:14:59<3:38:56, 410.51s/it] 28%|██▊       | 12/43 [1:21:44<3:31:13, 408.83s/it] 30%|███       | 13/43 [1:28:36<3:24:53, 409.77s/it] 33%|███▎      | 14/43 [1:35:26<3:18:09, 409.99s/it] 35%|███▍      | 15/43 [1:42:13<3:10:55, 409.11s/it] 37%|███▋      | 16/43 [1:49:02<3:04:00, 408.92s/it] 40%|███▉      | 17/43 [1:55:48<2:56:51, 408.12s/it] 42%|████▏     | 18/43 [2:02:35<2:49:54, 407.80s/it] 44%|████▍     | 19/43 [2:09:18<2:42:29, 406.25s/it] 47%|████▋     | 20/43 [2:15:56<2:34:52, 404.01s/it] 49%|████▉     | 21/43 [2:22:40<2:28:03, 403.80s/it] 51%|█████     | 22/43 [2:29:32<2:22:13, 406.36s/it] 53%|█████▎    | 23/43 [2:36:13<2:14:55, 404.78s/it] 56%|█████▌    | 24/43 [2:42:57<2:08:04, 404.47s/it] 58%|█████▊    | 25/43 [2:49:45<2:01:39, 405.54s/it] 60%|██████    | 26/43 [2:56:29<1:54:45, 405.00s/it] 63%|██████▎   | 27/43 [3:03:07<1:47:29, 403.10s/it] 65%|██████▌   | 28/43 [3:09:50<1:40:46, 403.09s/it] 67%|██████▋   | 29/43 [3:16:38<1:34:20, 404.30s/it] 70%|██████▉   | 30/43 [3:23:08<1:26:42, 400.16s/it] 72%|███████▏  | 31/43 [3:29:48<1:20:00, 400.03s/it] 74%|███████▍  | 32/43 [3:36:25<1:13:09, 399.03s/it] 77%|███████▋  | 33/43 [3:42:59<1:06:16, 397.62s/it] 79%|███████▉  | 34/43 [3:49:37<59:40, 397.82s/it]   81%|████████▏ | 35/43 [3:56:13<52:57, 397.16s/it] 84%|████████▎ | 36/43 [4:02:48<46:16, 396.67s/it] 86%|████████▌ | 37/43 [4:09:23<39:35, 395.98s/it] 88%|████████▊ | 38/43 [4:15:58<32:59, 395.90s/it] 91%|█████████ | 39/43 [4:22:34<26:23, 395.94s/it] 93%|█████████▎| 40/43 [4:29:12<19:49, 396.47s/it] 95%|█████████▌| 41/43 [4:35:46<13:11, 395.84s/it] 98%|█████████▊| 42/43 [4:42:22<06:35, 395.75s/it]100%|██████████| 43/43 [4:49:09<00:00, 398.98s/it]100%|██████████| 43/43 [4:49:09<00:00, 403.47s/it]
Avg comparisons: 245.0
Avg prompt tokens: 141326.90697674418
Avg completion tokens: 145246.90697674418
Avg time per query: 403.4660265057586
07
